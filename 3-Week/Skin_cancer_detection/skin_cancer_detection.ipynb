{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4h47ZwXYWUX",
        "outputId": "835d0e83-ccbe-4f23-a1e3-4c53fd0b09ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hasnainjaved/melanoma-skin-cancer-dataset-of-10000-images\n",
            "License(s): CC0-1.0\n",
            "Downloading melanoma-skin-cancer-dataset-of-10000-images.zip to d:\\CodeBackground\\AI-ML-Intern-tasks\\3-Week\\Skin_cancer_detection\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/98.7M [00:00<?, ?B/s]\n",
            "  1%|          | 1.00M/98.7M [00:01<01:58, 867kB/s]\n",
            "  2%|▏         | 2.00M/98.7M [00:01<01:01, 1.64MB/s]\n",
            "  3%|▎         | 3.00M/98.7M [00:01<00:42, 2.38MB/s]\n",
            "  4%|▍         | 4.00M/98.7M [00:01<00:34, 2.86MB/s]\n",
            "  5%|▌         | 5.00M/98.7M [00:02<00:38, 2.56MB/s]\n",
            "  6%|▌         | 6.00M/98.7M [00:02<00:38, 2.50MB/s]\n",
            "  7%|▋         | 7.00M/98.7M [00:03<00:43, 2.20MB/s]\n",
            "  8%|▊         | 8.00M/98.7M [00:04<00:51, 1.83MB/s]\n",
            "  9%|▉         | 9.00M/98.7M [00:05<01:06, 1.41MB/s]\n",
            " 10%|█         | 10.0M/98.7M [00:06<01:11, 1.30MB/s]\n",
            " 11%|█         | 11.0M/98.7M [00:06<01:04, 1.42MB/s]\n",
            " 12%|█▏        | 12.0M/98.7M [00:07<01:04, 1.42MB/s]\n",
            " 13%|█▎        | 13.0M/98.7M [00:08<01:01, 1.45MB/s]\n",
            " 14%|█▍        | 14.0M/98.7M [00:08<00:58, 1.53MB/s]\n",
            " 15%|█▌        | 15.0M/98.7M [00:09<00:55, 1.59MB/s]\n",
            " 16%|█▌        | 16.0M/98.7M [00:10<00:53, 1.63MB/s]\n",
            " 17%|█▋        | 17.0M/98.7M [00:10<00:51, 1.66MB/s]\n",
            " 18%|█▊        | 18.0M/98.7M [00:11<00:48, 1.74MB/s]\n",
            " 19%|█▉        | 19.0M/98.7M [00:11<00:47, 1.75MB/s]\n",
            " 20%|██        | 20.0M/98.7M [00:12<00:47, 1.74MB/s]\n",
            " 21%|██▏       | 21.0M/98.7M [00:13<00:50, 1.61MB/s]\n",
            " 22%|██▏       | 22.0M/98.7M [00:14<00:55, 1.45MB/s]\n",
            " 23%|██▎       | 23.0M/98.7M [00:14<00:58, 1.36MB/s]\n",
            " 24%|██▍       | 24.0M/98.7M [00:15<00:57, 1.36MB/s]\n",
            " 25%|██▌       | 25.0M/98.7M [00:16<00:47, 1.62MB/s]\n",
            " 26%|██▋       | 26.0M/98.7M [00:16<00:42, 1.81MB/s]\n",
            " 27%|██▋       | 27.0M/98.7M [00:17<00:40, 1.86MB/s]\n",
            " 28%|██▊       | 28.0M/98.7M [00:17<00:43, 1.71MB/s]\n",
            " 29%|██▉       | 29.0M/98.7M [00:18<00:50, 1.45MB/s]\n",
            " 30%|███       | 30.0M/98.7M [00:19<00:45, 1.59MB/s]\n",
            " 31%|███▏      | 31.0M/98.7M [00:19<00:42, 1.67MB/s]\n",
            " 32%|███▏      | 32.0M/98.7M [00:20<00:41, 1.69MB/s]\n",
            " 33%|███▎      | 33.0M/98.7M [00:21<00:40, 1.71MB/s]\n",
            " 34%|███▍      | 34.0M/98.7M [00:21<00:39, 1.73MB/s]\n",
            " 35%|███▌      | 35.0M/98.7M [00:22<00:38, 1.73MB/s]\n",
            " 36%|███▋      | 36.0M/98.7M [00:22<00:37, 1.76MB/s]\n",
            " 37%|███▋      | 37.0M/98.7M [00:23<00:36, 1.75MB/s]\n",
            " 38%|███▊      | 38.0M/98.7M [00:24<00:38, 1.67MB/s]\n",
            " 40%|███▉      | 39.0M/98.7M [00:25<00:48, 1.28MB/s]\n",
            " 41%|████      | 40.0M/98.7M [00:26<00:48, 1.26MB/s]\n",
            " 42%|████▏     | 41.0M/98.7M [00:26<00:38, 1.59MB/s]\n",
            " 43%|████▎     | 42.0M/98.7M [00:26<00:33, 1.79MB/s]\n",
            " 44%|████▎     | 43.0M/98.7M [00:27<00:32, 1.80MB/s]\n",
            " 45%|████▍     | 44.0M/98.7M [00:28<00:32, 1.79MB/s]\n",
            " 46%|████▌     | 45.0M/98.7M [00:28<00:31, 1.78MB/s]\n",
            " 47%|████▋     | 46.0M/98.7M [00:29<00:31, 1.77MB/s]\n",
            " 48%|████▊     | 47.0M/98.7M [00:30<00:36, 1.47MB/s]\n",
            " 49%|████▊     | 48.0M/98.7M [00:30<00:33, 1.58MB/s]\n",
            " 50%|████▉     | 49.0M/98.7M [00:31<00:31, 1.64MB/s]\n",
            " 51%|█████     | 50.0M/98.7M [00:31<00:30, 1.68MB/s]\n",
            " 52%|█████▏    | 51.0M/98.7M [00:32<00:29, 1.68MB/s]\n",
            " 53%|█████▎    | 52.0M/98.7M [00:33<00:28, 1.73MB/s]\n",
            " 54%|█████▎    | 53.0M/98.7M [00:33<00:27, 1.73MB/s]\n",
            " 55%|█████▍    | 54.0M/98.7M [00:34<00:28, 1.66MB/s]\n",
            " 56%|█████▌    | 55.0M/98.7M [00:35<00:32, 1.41MB/s]\n",
            " 57%|█████▋    | 56.0M/98.7M [00:36<00:32, 1.36MB/s]\n",
            " 58%|█████▊    | 57.0M/98.7M [00:36<00:26, 1.64MB/s]\n",
            " 59%|█████▉    | 58.0M/98.7M [00:37<00:24, 1.73MB/s]\n",
            " 60%|█████▉    | 59.0M/98.7M [00:37<00:23, 1.78MB/s]\n",
            " 61%|██████    | 60.0M/98.7M [00:38<00:23, 1.76MB/s]\n",
            " 62%|██████▏   | 61.0M/98.7M [00:39<00:25, 1.56MB/s]\n",
            " 63%|██████▎   | 62.0M/98.7M [00:39<00:22, 1.68MB/s]\n",
            " 64%|██████▍   | 63.0M/98.7M [00:40<00:24, 1.54MB/s]\n",
            " 65%|██████▍   | 64.0M/98.7M [00:41<00:25, 1.42MB/s]\n",
            " 66%|██████▌   | 65.0M/98.7M [00:42<00:26, 1.33MB/s]\n",
            " 67%|██████▋   | 66.0M/98.7M [00:42<00:22, 1.52MB/s]\n",
            " 68%|██████▊   | 67.0M/98.7M [00:43<00:18, 1.80MB/s]\n",
            " 69%|██████▉   | 68.0M/98.7M [00:43<00:16, 1.90MB/s]\n",
            " 70%|██████▉   | 69.0M/98.7M [00:44<00:16, 1.88MB/s]\n",
            " 71%|███████   | 70.0M/98.7M [00:45<00:20, 1.50MB/s]\n",
            " 72%|███████▏  | 71.0M/98.7M [00:45<00:18, 1.58MB/s]\n",
            " 73%|███████▎  | 72.0M/98.7M [00:46<00:16, 1.71MB/s]\n",
            " 74%|███████▍  | 73.0M/98.7M [00:46<00:15, 1.73MB/s]\n",
            " 75%|███████▍  | 74.0M/98.7M [00:47<00:15, 1.69MB/s]\n",
            " 76%|███████▌  | 75.0M/98.7M [00:47<00:14, 1.77MB/s]\n",
            " 77%|███████▋  | 76.0M/98.7M [00:48<00:13, 1.76MB/s]\n",
            " 78%|███████▊  | 77.0M/98.7M [00:49<00:13, 1.75MB/s]\n",
            " 79%|███████▉  | 78.0M/98.7M [00:49<00:12, 1.74MB/s]\n",
            " 80%|████████  | 79.0M/98.7M [00:50<00:11, 1.75MB/s]\n",
            " 81%|████████  | 80.0M/98.7M [00:51<00:14, 1.39MB/s]\n",
            " 82%|████████▏ | 81.0M/98.7M [00:52<00:13, 1.36MB/s]\n",
            " 83%|████████▎ | 82.0M/98.7M [00:52<00:10, 1.66MB/s]\n",
            " 84%|████████▍ | 83.0M/98.7M [00:53<00:08, 1.85MB/s]\n",
            " 85%|████████▌ | 84.0M/98.7M [00:53<00:08, 1.85MB/s]\n",
            " 86%|████████▌ | 85.0M/98.7M [00:54<00:08, 1.80MB/s]\n",
            " 87%|████████▋ | 86.0M/98.7M [00:54<00:07, 1.79MB/s]\n",
            " 88%|████████▊ | 87.0M/98.7M [00:55<00:06, 1.83MB/s]\n",
            " 89%|████████▉ | 88.0M/98.7M [00:55<00:06, 1.80MB/s]\n",
            " 90%|█████████ | 89.0M/98.7M [00:56<00:06, 1.59MB/s]\n",
            " 91%|█████████ | 90.0M/98.7M [00:57<00:06, 1.39MB/s]\n",
            " 92%|█████████▏| 91.0M/98.7M [00:58<00:04, 1.63MB/s]\n",
            " 93%|█████████▎| 92.0M/98.7M [00:58<00:03, 1.81MB/s]\n",
            " 94%|█████████▍| 93.0M/98.7M [00:59<00:03, 1.80MB/s]\n",
            " 95%|█████████▌| 94.0M/98.7M [00:59<00:02, 1.76MB/s]\n",
            " 96%|█████████▌| 95.0M/98.7M [01:00<00:02, 1.75MB/s]\n",
            " 97%|█████████▋| 96.0M/98.7M [01:00<00:01, 1.83MB/s]\n",
            " 98%|█████████▊| 97.0M/98.7M [01:01<00:01, 1.74MB/s]\n",
            " 99%|█████████▉| 98.0M/98.7M [01:02<00:00, 1.35MB/s]\n",
            "100%|██████████| 98.7M/98.7M [01:03<00:00, 1.41MB/s]\n",
            "100%|██████████| 98.7M/98.7M [01:03<00:00, 1.64MB/s]\n"
          ]
        }
      ],
      "source": [
        "#!/bin/bash\n",
        "!kaggle datasets download hasnainjaved/melanoma-skin-cancer-dataset-of-10000-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a4palHWUYu4w",
        "outputId": "64d67039-3dd1-464c-ad41-2ff9c1fc367a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files extracted to .\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = 'melanoma-skin-cancer-dataset-of-10000-images.zip'\n",
        "extract_to_path = '.'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(f\"Files extracted to {extract_to_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4p1J9B1Yyno",
        "outputId": "648941ca-e24d-40d3-897b-196990f03dce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing benign: 100%|██████████| 5000/5000 [00:16<00:00, 295.08it/s]\n",
            "Processing malignant: 100%|██████████| 4605/4605 [00:17<00:00, 268.75it/s]\n",
            "Processing benign: 100%|██████████| 500/500 [00:02<00:00, 229.02it/s]\n",
            "Processing malignant: 100%|██████████| 500/500 [00:02<00:00, 235.20it/s]\n",
            "2024-12-30 16:11:10,205 - INFO - \n",
            "Dataset Statistics:\n",
            "2024-12-30 16:11:10,267 - INFO - Benign training samples: 4605\n",
            "2024-12-30 16:11:10,273 - INFO - Malignant training samples: 4605\n",
            "2024-12-30 16:11:10,275 - INFO - Benign testing samples: 500\n",
            "2024-12-30 16:11:10,277 - INFO - Malignant testing samples: 500\n",
            "2024-12-30 16:11:10,277 - INFO - Total training samples: 9210\n",
            "2024-12-30 16:11:10,282 - INFO - Total testing samples: 1000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "class MelanomaDataProcessor:\n",
        "    def __init__(self, img_size: int = 50):\n",
        "        self.img_size = img_size\n",
        "        self.setup_logging()\n",
        "\n",
        "    def setup_logging(self):\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "            handlers=[\n",
        "                logging.FileHandler('melanoma_processing.log'),\n",
        "                logging.StreamHandler()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def load_and_process_image(self, image_path: str) -> np.ndarray:\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
        "\n",
        "        return cv2.resize(img, (self.img_size, self.img_size))\n",
        "\n",
        "    def process_directory(self, directory: str, label: np.ndarray) -> Tuple[List, List]:\n",
        "        \"\"\"\n",
        "        Process all images in a directory.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (images, labels)\n",
        "        \"\"\"\n",
        "        images = []\n",
        "        labels = []\n",
        "        directory_path = Path(directory)\n",
        "\n",
        "        if not directory_path.exists():\n",
        "            logging.error(f\"Directory not found: {directory}\")\n",
        "            return images, labels\n",
        "\n",
        "        files = list(directory_path.glob('*.jpg')) + list(directory_path.glob('*.png'))\n",
        "\n",
        "        for file_path in tqdm(files, desc=f\"Processing {directory_path.name}\"):\n",
        "            try:\n",
        "                img_array = self.load_and_process_image(str(file_path))\n",
        "                images.append(img_array)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                logging.warning(f\"Error processing {file_path}: {str(e)}\")\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    def process_dataset(self, data_config: Dict) -> Tuple[Tuple[np.ndarray, np.ndarray],\n",
        "                                                         Tuple[np.ndarray, np.ndarray]]:\n",
        "        \"\"\"\n",
        "        Process the entire dataset.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of ((train_images, train_labels), (test_images, test_labels))\n",
        "        \"\"\"\n",
        "        # Process training data\n",
        "        ben_train_images, ben_train_labels = self.process_directory(\n",
        "            data_config['ben_training_folder'],\n",
        "            np.array([1, 0])\n",
        "        )\n",
        "        mal_train_images, mal_train_labels = self.process_directory(\n",
        "            data_config['mal_training_folder'],\n",
        "            np.array([0, 1])\n",
        "        )\n",
        "\n",
        "        # Balance benign training data\n",
        "        ben_train_images = ben_train_images[:len(mal_train_images)]\n",
        "        ben_train_labels = ben_train_labels[:len(mal_train_labels)]\n",
        "\n",
        "        # Process testing data\n",
        "        ben_test_images, ben_test_labels = self.process_directory(\n",
        "            data_config['ben_testing_folder'],\n",
        "            np.array([1, 0])\n",
        "        )\n",
        "        mal_test_images, mal_test_labels = self.process_directory(\n",
        "            data_config['mal_testing_folder'],\n",
        "            np.array([0, 1])\n",
        "        )\n",
        "\n",
        "        # Combine images and labels\n",
        "        train_images = np.array(ben_train_images + mal_train_images)\n",
        "        train_labels = np.array(ben_train_labels + mal_train_labels)\n",
        "        test_images = np.array(ben_test_images + mal_test_images)\n",
        "        test_labels = np.array(ben_test_labels + mal_test_labels)\n",
        "\n",
        "        # Create shuffling index\n",
        "        train_shuffle_idx = np.random.permutation(len(train_images))\n",
        "        test_shuffle_idx = np.random.permutation(len(test_images))\n",
        "\n",
        "        # Shuffle both images and labels using the same index\n",
        "        train_images = train_images[train_shuffle_idx]\n",
        "        train_labels = train_labels[train_shuffle_idx]\n",
        "        test_images = test_images[test_shuffle_idx]\n",
        "        test_labels = test_labels[test_shuffle_idx]\n",
        "\n",
        "        # Log dataset statistics\n",
        "        self.log_dataset_stats(\n",
        "            len(ben_train_images),\n",
        "            len(mal_train_images),\n",
        "            len(ben_test_images),\n",
        "            len(mal_test_images)\n",
        "        )\n",
        "\n",
        "        return (train_images, train_labels), (test_images, test_labels)\n",
        "\n",
        "    def log_dataset_stats(self, ben_train: int, mal_train: int,\n",
        "                         ben_test: int, mal_test: int):\n",
        "        logging.info(\"\\nDataset Statistics:\")\n",
        "        logging.info(f\"Benign training samples: {ben_train}\")\n",
        "        logging.info(f\"Malignant training samples: {mal_train}\")\n",
        "        logging.info(f\"Benign testing samples: {ben_test}\")\n",
        "        logging.info(f\"Malignant testing samples: {mal_test}\")\n",
        "        logging.info(f\"Total training samples: {ben_train + mal_train}\")\n",
        "        logging.info(f\"Total testing samples: {ben_test + mal_test}\")\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    data_config = {\n",
        "        'ben_training_folder': \"melanoma_cancer_dataset/train/benign\",\n",
        "        'mal_training_folder': \"melanoma_cancer_dataset/train/malignant\",\n",
        "        'ben_testing_folder': \"melanoma_cancer_dataset/test/benign\",\n",
        "        'mal_testing_folder': \"melanoma_cancer_dataset/test/malignant\",\n",
        "    }\n",
        "\n",
        "    # Initialize and run processor\n",
        "    processor = MelanomaDataProcessor(img_size=224)\n",
        "    (train_images, train_labels), (test_images, test_labels) = processor.process_dataset(data_config)\n",
        "\n",
        "    # Save processed data\n",
        "    np.savez_compressed(\n",
        "        'melanoma_dataset.npz',\n",
        "        train_images=train_images,\n",
        "        train_labels=train_labels,\n",
        "        test_images=test_images,\n",
        "        test_labels=test_labels\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kyM9-pQietqi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLnboIxUev2U"
      },
      "outputs": [],
      "source": [
        "# statquest explanation video\n",
        "# https://www.youtube.com/watch?v=HGwBXDKFk9I\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Architecture](diagram.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lvaNF44yZj2a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KX6mxfQ4i6cq",
        "outputId": "100f0080-53e7-475e-a0c1-bb22edeab87e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Dark_Coder\\AppData\\Local\\Temp\\ipykernel_14364\\2347639631.py:23: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
            "  train_X = torch.Tensor([item for item in train_images]) / 255.0  # Normalize pixel values to [0, 1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1/2\n",
            "Epoch 1/2, Progress: 0.35% - Loss: 0.2512\n",
            "Epoch 1/2, Progress: 0.69% - Loss: 0.3284\n",
            "Epoch 1/2, Progress: 1.04% - Loss: 0.2704\n",
            "Epoch 1/2, Progress: 1.39% - Loss: 0.2615\n",
            "Epoch 1/2, Progress: 1.74% - Loss: 0.2563\n",
            "Epoch 1/2, Progress: 2.08% - Loss: 0.2535\n",
            "Epoch 1/2, Progress: 2.43% - Loss: 0.2466\n",
            "Epoch 1/2, Progress: 2.78% - Loss: 0.2478\n",
            "Epoch 1/2, Progress: 3.13% - Loss: 0.2445\n",
            "Epoch 1/2, Progress: 3.47% - Loss: 0.2373\n",
            "Epoch 1/2, Progress: 3.82% - Loss: 0.2388\n",
            "Epoch 1/2, Progress: 4.17% - Loss: 0.2328\n",
            "Epoch 1/2, Progress: 4.52% - Loss: 0.2178\n",
            "Epoch 1/2, Progress: 4.86% - Loss: 0.2649\n",
            "Epoch 1/2, Progress: 5.21% - Loss: 0.2212\n",
            "Epoch 1/2, Progress: 5.56% - Loss: 0.2214\n",
            "Epoch 1/2, Progress: 5.91% - Loss: 0.2270\n",
            "Epoch 1/2, Progress: 6.25% - Loss: 0.1989\n",
            "Epoch 1/2, Progress: 6.60% - Loss: 0.2317\n",
            "Epoch 1/2, Progress: 6.95% - Loss: 0.2014\n",
            "Epoch 1/2, Progress: 7.30% - Loss: 0.2027\n",
            "Epoch 1/2, Progress: 7.64% - Loss: 0.2368\n",
            "Epoch 1/2, Progress: 7.99% - Loss: 0.2243\n",
            "Epoch 1/2, Progress: 8.34% - Loss: 0.1811\n",
            "Epoch 1/2, Progress: 8.69% - Loss: 0.3066\n",
            "Epoch 1/2, Progress: 9.03% - Loss: 0.2363\n",
            "Epoch 1/2, Progress: 9.38% - Loss: 0.1798\n",
            "Epoch 1/2, Progress: 9.73% - Loss: 0.2095\n",
            "Epoch 1/2, Progress: 10.08% - Loss: 0.2081\n",
            "Epoch 1/2, Progress: 10.42% - Loss: 0.2439\n",
            "Epoch 1/2, Progress: 10.77% - Loss: 0.2077\n",
            "Epoch 1/2, Progress: 11.12% - Loss: 0.2190\n",
            "Epoch 1/2, Progress: 11.47% - Loss: 0.1959\n",
            "Epoch 1/2, Progress: 11.81% - Loss: 0.1895\n",
            "Epoch 1/2, Progress: 12.16% - Loss: 0.2297\n",
            "Epoch 1/2, Progress: 12.51% - Loss: 0.1854\n",
            "Epoch 1/2, Progress: 12.86% - Loss: 0.1860\n",
            "Epoch 1/2, Progress: 13.20% - Loss: 0.2055\n",
            "Epoch 1/2, Progress: 13.55% - Loss: 0.1756\n",
            "Epoch 1/2, Progress: 13.90% - Loss: 0.1835\n",
            "Epoch 1/2, Progress: 14.25% - Loss: 0.1565\n",
            "Epoch 1/2, Progress: 14.59% - Loss: 0.2048\n",
            "Epoch 1/2, Progress: 14.94% - Loss: 0.1391\n",
            "Epoch 1/2, Progress: 15.29% - Loss: 0.1716\n",
            "Epoch 1/2, Progress: 15.64% - Loss: 0.2092\n",
            "Epoch 1/2, Progress: 15.98% - Loss: 0.1611\n",
            "Epoch 1/2, Progress: 16.33% - Loss: 0.1446\n",
            "Epoch 1/2, Progress: 16.68% - Loss: 0.1709\n",
            "Epoch 1/2, Progress: 17.02% - Loss: 0.1395\n",
            "Epoch 1/2, Progress: 17.37% - Loss: 0.1681\n",
            "Epoch 1/2, Progress: 17.72% - Loss: 0.1177\n",
            "Epoch 1/2, Progress: 18.07% - Loss: 0.1311\n",
            "Epoch 1/2, Progress: 18.41% - Loss: 0.1304\n",
            "Epoch 1/2, Progress: 18.76% - Loss: 0.2014\n",
            "Epoch 1/2, Progress: 19.11% - Loss: 0.1264\n",
            "Epoch 1/2, Progress: 19.46% - Loss: 0.1101\n",
            "Epoch 1/2, Progress: 19.80% - Loss: 0.1442\n",
            "Epoch 1/2, Progress: 20.15% - Loss: 0.2166\n",
            "Epoch 1/2, Progress: 20.50% - Loss: 0.1610\n",
            "Epoch 1/2, Progress: 20.85% - Loss: 0.1643\n",
            "Epoch 1/2, Progress: 21.19% - Loss: 0.1050\n",
            "Epoch 1/2, Progress: 21.54% - Loss: 0.1197\n",
            "Epoch 1/2, Progress: 21.89% - Loss: 0.1538\n",
            "Epoch 1/2, Progress: 22.24% - Loss: 0.1821\n",
            "Epoch 1/2, Progress: 22.58% - Loss: 0.1572\n",
            "Epoch 1/2, Progress: 22.93% - Loss: 0.0812\n",
            "Epoch 1/2, Progress: 23.28% - Loss: 0.1714\n",
            "Epoch 1/2, Progress: 23.63% - Loss: 0.1905\n",
            "Epoch 1/2, Progress: 23.97% - Loss: 0.1967\n",
            "Epoch 1/2, Progress: 24.32% - Loss: 0.1653\n",
            "Epoch 1/2, Progress: 24.67% - Loss: 0.1501\n",
            "Epoch 1/2, Progress: 25.02% - Loss: 0.1463\n",
            "Epoch 1/2, Progress: 25.36% - Loss: 0.2156\n",
            "Epoch 1/2, Progress: 25.71% - Loss: 0.2330\n",
            "Epoch 1/2, Progress: 26.06% - Loss: 0.1678\n",
            "Epoch 1/2, Progress: 26.41% - Loss: 0.1370\n",
            "Epoch 1/2, Progress: 26.75% - Loss: 0.1523\n",
            "Epoch 1/2, Progress: 27.10% - Loss: 0.1471\n",
            "Epoch 1/2, Progress: 27.45% - Loss: 0.1695\n",
            "Epoch 1/2, Progress: 27.80% - Loss: 0.1693\n",
            "Epoch 1/2, Progress: 28.14% - Loss: 0.1431\n",
            "Epoch 1/2, Progress: 28.49% - Loss: 0.1242\n",
            "Epoch 1/2, Progress: 28.84% - Loss: 0.1319\n",
            "Epoch 1/2, Progress: 29.19% - Loss: 0.1701\n",
            "Epoch 1/2, Progress: 29.53% - Loss: 0.1508\n",
            "Epoch 1/2, Progress: 29.88% - Loss: 0.1118\n",
            "Epoch 1/2, Progress: 30.23% - Loss: 0.1458\n",
            "Epoch 1/2, Progress: 30.58% - Loss: 0.1690\n",
            "Epoch 1/2, Progress: 30.92% - Loss: 0.1168\n",
            "Epoch 1/2, Progress: 31.27% - Loss: 0.1705\n",
            "Epoch 1/2, Progress: 31.62% - Loss: 0.1706\n",
            "Epoch 1/2, Progress: 31.97% - Loss: 0.2484\n",
            "Epoch 1/2, Progress: 32.31% - Loss: 0.1407\n",
            "Epoch 1/2, Progress: 32.66% - Loss: 0.1335\n",
            "Epoch 1/2, Progress: 33.01% - Loss: 0.0907\n",
            "Epoch 1/2, Progress: 33.36% - Loss: 0.1047\n",
            "Epoch 1/2, Progress: 33.70% - Loss: 0.1665\n",
            "Epoch 1/2, Progress: 34.05% - Loss: 0.1626\n",
            "Epoch 1/2, Progress: 34.40% - Loss: 0.1295\n",
            "Epoch 1/2, Progress: 34.74% - Loss: 0.1376\n",
            "Epoch 1/2, Progress: 35.09% - Loss: 0.1773\n",
            "Epoch 1/2, Progress: 35.44% - Loss: 0.1189\n",
            "Epoch 1/2, Progress: 35.79% - Loss: 0.1570\n",
            "Epoch 1/2, Progress: 36.13% - Loss: 0.1239\n",
            "Epoch 1/2, Progress: 36.48% - Loss: 0.1054\n",
            "Epoch 1/2, Progress: 36.83% - Loss: 0.1552\n",
            "Epoch 1/2, Progress: 37.18% - Loss: 0.1617\n",
            "Epoch 1/2, Progress: 37.52% - Loss: 0.1611\n",
            "Epoch 1/2, Progress: 37.87% - Loss: 0.1220\n",
            "Epoch 1/2, Progress: 38.22% - Loss: 0.1046\n",
            "Epoch 1/2, Progress: 38.57% - Loss: 0.1434\n",
            "Epoch 1/2, Progress: 38.91% - Loss: 0.1202\n",
            "Epoch 1/2, Progress: 39.26% - Loss: 0.1732\n",
            "Epoch 1/2, Progress: 39.61% - Loss: 0.1072\n",
            "Epoch 1/2, Progress: 39.96% - Loss: 0.1602\n",
            "Epoch 1/2, Progress: 40.30% - Loss: 0.0907\n",
            "Epoch 1/2, Progress: 40.65% - Loss: 0.1259\n",
            "Epoch 1/2, Progress: 41.00% - Loss: 0.1507\n",
            "Epoch 1/2, Progress: 41.35% - Loss: 0.1366\n",
            "Epoch 1/2, Progress: 41.69% - Loss: 0.1704\n",
            "Epoch 1/2, Progress: 42.04% - Loss: 0.1729\n",
            "Epoch 1/2, Progress: 42.39% - Loss: 0.1227\n",
            "Epoch 1/2, Progress: 42.74% - Loss: 0.1880\n",
            "Epoch 1/2, Progress: 43.08% - Loss: 0.1508\n",
            "Epoch 1/2, Progress: 43.43% - Loss: 0.1670\n",
            "Epoch 1/2, Progress: 43.78% - Loss: 0.2361\n",
            "Epoch 1/2, Progress: 44.13% - Loss: 0.1558\n",
            "Epoch 1/2, Progress: 44.47% - Loss: 0.1511\n",
            "Epoch 1/2, Progress: 44.82% - Loss: 0.1549\n",
            "Epoch 1/2, Progress: 45.17% - Loss: 0.1342\n",
            "Epoch 1/2, Progress: 45.52% - Loss: 0.1346\n",
            "Epoch 1/2, Progress: 45.86% - Loss: 0.1466\n",
            "Epoch 1/2, Progress: 46.21% - Loss: 0.0960\n",
            "Epoch 1/2, Progress: 46.56% - Loss: 0.0985\n",
            "Epoch 1/2, Progress: 46.91% - Loss: 0.1845\n",
            "Epoch 1/2, Progress: 47.25% - Loss: 0.1992\n",
            "Epoch 1/2, Progress: 47.60% - Loss: 0.0936\n",
            "Epoch 1/2, Progress: 47.95% - Loss: 0.1918\n",
            "Epoch 1/2, Progress: 48.30% - Loss: 0.1361\n",
            "Epoch 1/2, Progress: 48.64% - Loss: 0.1421\n",
            "Epoch 1/2, Progress: 48.99% - Loss: 0.1656\n",
            "Epoch 1/2, Progress: 49.34% - Loss: 0.1359\n",
            "Epoch 1/2, Progress: 49.69% - Loss: 0.1472\n",
            "Epoch 1/2, Progress: 50.03% - Loss: 0.1212\n",
            "Epoch 1/2, Progress: 50.38% - Loss: 0.1046\n",
            "Epoch 1/2, Progress: 50.73% - Loss: 0.1686\n",
            "Epoch 1/2, Progress: 51.07% - Loss: 0.1149\n",
            "Epoch 1/2, Progress: 51.42% - Loss: 0.1364\n",
            "Epoch 1/2, Progress: 51.77% - Loss: 0.1708\n",
            "Epoch 1/2, Progress: 52.12% - Loss: 0.1606\n",
            "Epoch 1/2, Progress: 52.46% - Loss: 0.1602\n",
            "Epoch 1/2, Progress: 52.81% - Loss: 0.1205\n",
            "Epoch 1/2, Progress: 53.16% - Loss: 0.1286\n",
            "Epoch 1/2, Progress: 53.51% - Loss: 0.1058\n",
            "Epoch 1/2, Progress: 53.85% - Loss: 0.1153\n",
            "Epoch 1/2, Progress: 54.20% - Loss: 0.2009\n",
            "Epoch 1/2, Progress: 54.55% - Loss: 0.1033\n",
            "Epoch 1/2, Progress: 54.90% - Loss: 0.1384\n",
            "Epoch 1/2, Progress: 55.24% - Loss: 0.1618\n",
            "Epoch 1/2, Progress: 55.59% - Loss: 0.0779\n",
            "Epoch 1/2, Progress: 55.94% - Loss: 0.1135\n",
            "Epoch 1/2, Progress: 56.29% - Loss: 0.1641\n",
            "Epoch 1/2, Progress: 56.63% - Loss: 0.1004\n",
            "Epoch 1/2, Progress: 56.98% - Loss: 0.1594\n",
            "Epoch 1/2, Progress: 57.33% - Loss: 0.1122\n",
            "Epoch 1/2, Progress: 57.68% - Loss: 0.1860\n",
            "Epoch 1/2, Progress: 58.02% - Loss: 0.1431\n",
            "Epoch 1/2, Progress: 58.37% - Loss: 0.0958\n",
            "Epoch 1/2, Progress: 58.72% - Loss: 0.1246\n",
            "Epoch 1/2, Progress: 59.07% - Loss: 0.1294\n",
            "Epoch 1/2, Progress: 59.41% - Loss: 0.1366\n",
            "Epoch 1/2, Progress: 59.76% - Loss: 0.1246\n",
            "Epoch 1/2, Progress: 60.11% - Loss: 0.0893\n",
            "Epoch 1/2, Progress: 60.46% - Loss: 0.1079\n",
            "Epoch 1/2, Progress: 60.80% - Loss: 0.1091\n",
            "Epoch 1/2, Progress: 61.15% - Loss: 0.0971\n",
            "Epoch 1/2, Progress: 61.50% - Loss: 0.2127\n",
            "Epoch 1/2, Progress: 61.85% - Loss: 0.0965\n",
            "Epoch 1/2, Progress: 62.19% - Loss: 0.1395\n",
            "Epoch 1/2, Progress: 62.54% - Loss: 0.1269\n",
            "Epoch 1/2, Progress: 62.89% - Loss: 0.1005\n",
            "Epoch 1/2, Progress: 63.24% - Loss: 0.1239\n",
            "Epoch 1/2, Progress: 63.58% - Loss: 0.1322\n",
            "Epoch 1/2, Progress: 63.93% - Loss: 0.0635\n",
            "Epoch 1/2, Progress: 64.28% - Loss: 0.0998\n",
            "Epoch 1/2, Progress: 64.63% - Loss: 0.1177\n",
            "Epoch 1/2, Progress: 64.97% - Loss: 0.1180\n",
            "Epoch 1/2, Progress: 65.32% - Loss: 0.1347\n",
            "Epoch 1/2, Progress: 65.67% - Loss: 0.1731\n",
            "Epoch 1/2, Progress: 66.02% - Loss: 0.1620\n",
            "Epoch 1/2, Progress: 66.36% - Loss: 0.1681\n",
            "Epoch 1/2, Progress: 66.71% - Loss: 0.1344\n",
            "Epoch 1/2, Progress: 67.06% - Loss: 0.1695\n",
            "Epoch 1/2, Progress: 67.40% - Loss: 0.0897\n",
            "Epoch 1/2, Progress: 67.75% - Loss: 0.0958\n",
            "Epoch 1/2, Progress: 68.10% - Loss: 0.0660\n",
            "Epoch 1/2, Progress: 68.45% - Loss: 0.1438\n",
            "Epoch 1/2, Progress: 68.79% - Loss: 0.1171\n",
            "Epoch 1/2, Progress: 69.14% - Loss: 0.1843\n",
            "Epoch 1/2, Progress: 69.49% - Loss: 0.1195\n",
            "Epoch 1/2, Progress: 69.84% - Loss: 0.1581\n",
            "Epoch 1/2, Progress: 70.18% - Loss: 0.1122\n",
            "Epoch 1/2, Progress: 70.53% - Loss: 0.1797\n",
            "Epoch 1/2, Progress: 70.88% - Loss: 0.1095\n",
            "Epoch 1/2, Progress: 71.23% - Loss: 0.1055\n",
            "Epoch 1/2, Progress: 71.57% - Loss: 0.1989\n",
            "Epoch 1/2, Progress: 71.92% - Loss: 0.1586\n",
            "Epoch 1/2, Progress: 72.27% - Loss: 0.1465\n",
            "Epoch 1/2, Progress: 72.62% - Loss: 0.1138\n",
            "Epoch 1/2, Progress: 72.96% - Loss: 0.1516\n",
            "Epoch 1/2, Progress: 73.31% - Loss: 0.1079\n",
            "Epoch 1/2, Progress: 73.66% - Loss: 0.1129\n",
            "Epoch 1/2, Progress: 74.01% - Loss: 0.1655\n",
            "Epoch 1/2, Progress: 74.35% - Loss: 0.0934\n",
            "Epoch 1/2, Progress: 74.70% - Loss: 0.1353\n",
            "Epoch 1/2, Progress: 75.05% - Loss: 0.1216\n",
            "Epoch 1/2, Progress: 75.40% - Loss: 0.1656\n",
            "Epoch 1/2, Progress: 75.74% - Loss: 0.1312\n",
            "Epoch 1/2, Progress: 76.09% - Loss: 0.1462\n",
            "Epoch 1/2, Progress: 76.44% - Loss: 0.1194\n",
            "Epoch 1/2, Progress: 76.79% - Loss: 0.0853\n",
            "Epoch 1/2, Progress: 77.13% - Loss: 0.1128\n",
            "Epoch 1/2, Progress: 77.48% - Loss: 0.1603\n",
            "Epoch 1/2, Progress: 77.83% - Loss: 0.1095\n",
            "Epoch 1/2, Progress: 78.18% - Loss: 0.0995\n",
            "Epoch 1/2, Progress: 78.52% - Loss: 0.1391\n",
            "Epoch 1/2, Progress: 78.87% - Loss: 0.1296\n",
            "Epoch 1/2, Progress: 79.22% - Loss: 0.1011\n",
            "Epoch 1/2, Progress: 79.57% - Loss: 0.0478\n",
            "Epoch 1/2, Progress: 79.91% - Loss: 0.1533\n",
            "Epoch 1/2, Progress: 80.26% - Loss: 0.0783\n",
            "Epoch 1/2, Progress: 80.61% - Loss: 0.1010\n",
            "Epoch 1/2, Progress: 80.96% - Loss: 0.1650\n",
            "Epoch 1/2, Progress: 81.30% - Loss: 0.1140\n",
            "Epoch 1/2, Progress: 81.65% - Loss: 0.1576\n",
            "Epoch 1/2, Progress: 82.00% - Loss: 0.1328\n",
            "Epoch 1/2, Progress: 82.35% - Loss: 0.1153\n",
            "Epoch 1/2, Progress: 82.69% - Loss: 0.1523\n",
            "Epoch 1/2, Progress: 83.04% - Loss: 0.0769\n",
            "Epoch 1/2, Progress: 83.39% - Loss: 0.1593\n",
            "Epoch 1/2, Progress: 83.74% - Loss: 0.0899\n",
            "Epoch 1/2, Progress: 84.08% - Loss: 0.1985\n",
            "Epoch 1/2, Progress: 84.43% - Loss: 0.1388\n",
            "Epoch 1/2, Progress: 84.78% - Loss: 0.1237\n",
            "Epoch 1/2, Progress: 85.12% - Loss: 0.1667\n",
            "Epoch 1/2, Progress: 85.47% - Loss: 0.0923\n",
            "Epoch 1/2, Progress: 85.82% - Loss: 0.0827\n",
            "Epoch 1/2, Progress: 86.17% - Loss: 0.0887\n",
            "Epoch 1/2, Progress: 86.51% - Loss: 0.1011\n",
            "Epoch 1/2, Progress: 86.86% - Loss: 0.1516\n",
            "Epoch 1/2, Progress: 87.21% - Loss: 0.1405\n",
            "Epoch 1/2, Progress: 87.56% - Loss: 0.0816\n",
            "Epoch 1/2, Progress: 87.90% - Loss: 0.0841\n",
            "Epoch 1/2, Progress: 88.25% - Loss: 0.1015\n",
            "Epoch 1/2, Progress: 88.60% - Loss: 0.1807\n",
            "Epoch 1/2, Progress: 88.95% - Loss: 0.1411\n",
            "Epoch 1/2, Progress: 89.29% - Loss: 0.1206\n",
            "Epoch 1/2, Progress: 89.64% - Loss: 0.1070\n",
            "Epoch 1/2, Progress: 89.99% - Loss: 0.1878\n",
            "Epoch 1/2, Progress: 90.34% - Loss: 0.1362\n",
            "Epoch 1/2, Progress: 90.68% - Loss: 0.1102\n",
            "Epoch 1/2, Progress: 91.03% - Loss: 0.0734\n",
            "Epoch 1/2, Progress: 91.38% - Loss: 0.1498\n",
            "Epoch 1/2, Progress: 91.73% - Loss: 0.1213\n",
            "Epoch 1/2, Progress: 92.07% - Loss: 0.1171\n",
            "Epoch 1/2, Progress: 92.42% - Loss: 0.1276\n",
            "Epoch 1/2, Progress: 92.77% - Loss: 0.1373\n",
            "Epoch 1/2, Progress: 93.12% - Loss: 0.1734\n",
            "Epoch 1/2, Progress: 93.46% - Loss: 0.1271\n",
            "Epoch 1/2, Progress: 93.81% - Loss: 0.1221\n",
            "Epoch 1/2, Progress: 94.16% - Loss: 0.1389\n",
            "Epoch 1/2, Progress: 94.51% - Loss: 0.1364\n",
            "Epoch 1/2, Progress: 94.85% - Loss: 0.1512\n",
            "Epoch 1/2, Progress: 95.20% - Loss: 0.1042\n",
            "Epoch 1/2, Progress: 95.55% - Loss: 0.1060\n",
            "Epoch 1/2, Progress: 95.90% - Loss: 0.0925\n",
            "Epoch 1/2, Progress: 96.24% - Loss: 0.1514\n",
            "Epoch 1/2, Progress: 96.59% - Loss: 0.1149\n",
            "Epoch 1/2, Progress: 96.94% - Loss: 0.1588\n",
            "Epoch 1/2, Progress: 97.29% - Loss: 0.1242\n",
            "Epoch 1/2, Progress: 97.63% - Loss: 0.1488\n",
            "Epoch 1/2, Progress: 97.98% - Loss: 0.0914\n",
            "Epoch 1/2, Progress: 98.33% - Loss: 0.0943\n",
            "Epoch 1/2, Progress: 98.68% - Loss: 0.1631\n",
            "Epoch 1/2, Progress: 99.02% - Loss: 0.1312\n",
            "Epoch 1/2, Progress: 99.37% - Loss: 0.1038\n",
            "Epoch 1/2, Progress: 99.72% - Loss: 0.1925\n",
            "Epoch 1/2, Progress: 100.07% - Loss: 0.1046\n",
            "Starting epoch 2/2\n",
            "Epoch 2/2, Progress: 0.35% - Loss: 0.1199\n",
            "Epoch 2/2, Progress: 0.69% - Loss: 0.1513\n",
            "Epoch 2/2, Progress: 1.04% - Loss: 0.0509\n",
            "Epoch 2/2, Progress: 1.39% - Loss: 0.2064\n",
            "Epoch 2/2, Progress: 1.74% - Loss: 0.1423\n",
            "Epoch 2/2, Progress: 2.08% - Loss: 0.1219\n",
            "Epoch 2/2, Progress: 2.43% - Loss: 0.1599\n",
            "Epoch 2/2, Progress: 2.78% - Loss: 0.1225\n",
            "Epoch 2/2, Progress: 3.13% - Loss: 0.1300\n",
            "Epoch 2/2, Progress: 3.47% - Loss: 0.1855\n",
            "Epoch 2/2, Progress: 3.82% - Loss: 0.1555\n",
            "Epoch 2/2, Progress: 4.17% - Loss: 0.1137\n",
            "Epoch 2/2, Progress: 4.52% - Loss: 0.1096\n",
            "Epoch 2/2, Progress: 4.86% - Loss: 0.1023\n",
            "Epoch 2/2, Progress: 5.21% - Loss: 0.1039\n",
            "Epoch 2/2, Progress: 5.56% - Loss: 0.0903\n",
            "Epoch 2/2, Progress: 5.91% - Loss: 0.1746\n",
            "Epoch 2/2, Progress: 6.25% - Loss: 0.1145\n",
            "Epoch 2/2, Progress: 6.60% - Loss: 0.1046\n",
            "Epoch 2/2, Progress: 6.95% - Loss: 0.1413\n",
            "Epoch 2/2, Progress: 7.30% - Loss: 0.1084\n",
            "Epoch 2/2, Progress: 7.64% - Loss: 0.0983\n",
            "Epoch 2/2, Progress: 7.99% - Loss: 0.1708\n",
            "Epoch 2/2, Progress: 8.34% - Loss: 0.1120\n",
            "Epoch 2/2, Progress: 8.69% - Loss: 0.0850\n",
            "Epoch 2/2, Progress: 9.03% - Loss: 0.1275\n",
            "Epoch 2/2, Progress: 9.38% - Loss: 0.0947\n",
            "Epoch 2/2, Progress: 9.73% - Loss: 0.0802\n",
            "Epoch 2/2, Progress: 10.08% - Loss: 0.1303\n",
            "Epoch 2/2, Progress: 10.42% - Loss: 0.1459\n",
            "Epoch 2/2, Progress: 10.77% - Loss: 0.1672\n",
            "Epoch 2/2, Progress: 11.12% - Loss: 0.1016\n",
            "Epoch 2/2, Progress: 11.47% - Loss: 0.1528\n",
            "Epoch 2/2, Progress: 11.81% - Loss: 0.1103\n",
            "Epoch 2/2, Progress: 12.16% - Loss: 0.1225\n",
            "Epoch 2/2, Progress: 12.51% - Loss: 0.0876\n",
            "Epoch 2/2, Progress: 12.86% - Loss: 0.1102\n",
            "Epoch 2/2, Progress: 13.20% - Loss: 0.1018\n",
            "Epoch 2/2, Progress: 13.55% - Loss: 0.1017\n",
            "Epoch 2/2, Progress: 13.90% - Loss: 0.1024\n",
            "Epoch 2/2, Progress: 14.25% - Loss: 0.0633\n",
            "Epoch 2/2, Progress: 14.59% - Loss: 0.1222\n",
            "Epoch 2/2, Progress: 14.94% - Loss: 0.1393\n",
            "Epoch 2/2, Progress: 15.29% - Loss: 0.1041\n",
            "Epoch 2/2, Progress: 15.64% - Loss: 0.0952\n",
            "Epoch 2/2, Progress: 15.98% - Loss: 0.1199\n",
            "Epoch 2/2, Progress: 16.33% - Loss: 0.1440\n",
            "Epoch 2/2, Progress: 16.68% - Loss: 0.1397\n",
            "Epoch 2/2, Progress: 17.02% - Loss: 0.0704\n",
            "Epoch 2/2, Progress: 17.37% - Loss: 0.0875\n",
            "Epoch 2/2, Progress: 17.72% - Loss: 0.0605\n",
            "Epoch 2/2, Progress: 18.07% - Loss: 0.0845\n",
            "Epoch 2/2, Progress: 18.41% - Loss: 0.0650\n",
            "Epoch 2/2, Progress: 18.76% - Loss: 0.1132\n",
            "Epoch 2/2, Progress: 19.11% - Loss: 0.1046\n",
            "Epoch 2/2, Progress: 19.46% - Loss: 0.0617\n",
            "Epoch 2/2, Progress: 19.80% - Loss: 0.1377\n",
            "Epoch 2/2, Progress: 20.15% - Loss: 0.1250\n",
            "Epoch 2/2, Progress: 20.50% - Loss: 0.0818\n",
            "Epoch 2/2, Progress: 20.85% - Loss: 0.1021\n",
            "Epoch 2/2, Progress: 21.19% - Loss: 0.0726\n",
            "Epoch 2/2, Progress: 21.54% - Loss: 0.0565\n",
            "Epoch 2/2, Progress: 21.89% - Loss: 0.1148\n",
            "Epoch 2/2, Progress: 22.24% - Loss: 0.1265\n",
            "Epoch 2/2, Progress: 22.58% - Loss: 0.1127\n",
            "Epoch 2/2, Progress: 22.93% - Loss: 0.0839\n",
            "Epoch 2/2, Progress: 23.28% - Loss: 0.1678\n",
            "Epoch 2/2, Progress: 23.63% - Loss: 0.1013\n",
            "Epoch 2/2, Progress: 23.97% - Loss: 0.1530\n",
            "Epoch 2/2, Progress: 24.32% - Loss: 0.0895\n",
            "Epoch 2/2, Progress: 24.67% - Loss: 0.1325\n",
            "Epoch 2/2, Progress: 25.02% - Loss: 0.0975\n",
            "Epoch 2/2, Progress: 25.36% - Loss: 0.1521\n",
            "Epoch 2/2, Progress: 25.71% - Loss: 0.1527\n",
            "Epoch 2/2, Progress: 26.06% - Loss: 0.1204\n",
            "Epoch 2/2, Progress: 26.41% - Loss: 0.1410\n",
            "Epoch 2/2, Progress: 26.75% - Loss: 0.0658\n",
            "Epoch 2/2, Progress: 27.10% - Loss: 0.1419\n",
            "Epoch 2/2, Progress: 27.45% - Loss: 0.1184\n",
            "Epoch 2/2, Progress: 27.80% - Loss: 0.1373\n",
            "Epoch 2/2, Progress: 28.14% - Loss: 0.0715\n",
            "Epoch 2/2, Progress: 28.49% - Loss: 0.1062\n",
            "Epoch 2/2, Progress: 28.84% - Loss: 0.1252\n",
            "Epoch 2/2, Progress: 29.19% - Loss: 0.1446\n",
            "Epoch 2/2, Progress: 29.53% - Loss: 0.1176\n",
            "Epoch 2/2, Progress: 29.88% - Loss: 0.0609\n",
            "Epoch 2/2, Progress: 30.23% - Loss: 0.1596\n",
            "Epoch 2/2, Progress: 30.58% - Loss: 0.0970\n",
            "Epoch 2/2, Progress: 30.92% - Loss: 0.1370\n",
            "Epoch 2/2, Progress: 31.27% - Loss: 0.1169\n",
            "Epoch 2/2, Progress: 31.62% - Loss: 0.1184\n",
            "Epoch 2/2, Progress: 31.97% - Loss: 0.1669\n",
            "Epoch 2/2, Progress: 32.31% - Loss: 0.1237\n",
            "Epoch 2/2, Progress: 32.66% - Loss: 0.0864\n",
            "Epoch 2/2, Progress: 33.01% - Loss: 0.0983\n",
            "Epoch 2/2, Progress: 33.36% - Loss: 0.0580\n",
            "Epoch 2/2, Progress: 33.70% - Loss: 0.1333\n",
            "Epoch 2/2, Progress: 34.05% - Loss: 0.1213\n",
            "Epoch 2/2, Progress: 34.40% - Loss: 0.1079\n",
            "Epoch 2/2, Progress: 34.74% - Loss: 0.1260\n",
            "Epoch 2/2, Progress: 35.09% - Loss: 0.1265\n",
            "Epoch 2/2, Progress: 35.44% - Loss: 0.1150\n",
            "Epoch 2/2, Progress: 35.79% - Loss: 0.1529\n",
            "Epoch 2/2, Progress: 36.13% - Loss: 0.1156\n",
            "Epoch 2/2, Progress: 36.48% - Loss: 0.0696\n",
            "Epoch 2/2, Progress: 36.83% - Loss: 0.1354\n",
            "Epoch 2/2, Progress: 37.18% - Loss: 0.1349\n",
            "Epoch 2/2, Progress: 37.52% - Loss: 0.1285\n",
            "Epoch 2/2, Progress: 37.87% - Loss: 0.0964\n",
            "Epoch 2/2, Progress: 38.22% - Loss: 0.0923\n",
            "Epoch 2/2, Progress: 38.57% - Loss: 0.1263\n",
            "Epoch 2/2, Progress: 38.91% - Loss: 0.0705\n",
            "Epoch 2/2, Progress: 39.26% - Loss: 0.1741\n",
            "Epoch 2/2, Progress: 39.61% - Loss: 0.0764\n",
            "Epoch 2/2, Progress: 39.96% - Loss: 0.1464\n",
            "Epoch 2/2, Progress: 40.30% - Loss: 0.0878\n",
            "Epoch 2/2, Progress: 40.65% - Loss: 0.1180\n",
            "Epoch 2/2, Progress: 41.00% - Loss: 0.0887\n",
            "Epoch 2/2, Progress: 41.35% - Loss: 0.0602\n",
            "Epoch 2/2, Progress: 41.69% - Loss: 0.0713\n",
            "Epoch 2/2, Progress: 42.04% - Loss: 0.1346\n",
            "Epoch 2/2, Progress: 42.39% - Loss: 0.0616\n",
            "Epoch 2/2, Progress: 42.74% - Loss: 0.1157\n",
            "Epoch 2/2, Progress: 43.08% - Loss: 0.1428\n",
            "Epoch 2/2, Progress: 43.43% - Loss: 0.0967\n",
            "Epoch 2/2, Progress: 43.78% - Loss: 0.1476\n",
            "Epoch 2/2, Progress: 44.13% - Loss: 0.0859\n",
            "Epoch 2/2, Progress: 44.47% - Loss: 0.1169\n",
            "Epoch 2/2, Progress: 44.82% - Loss: 0.0794\n",
            "Epoch 2/2, Progress: 45.17% - Loss: 0.1152\n",
            "Epoch 2/2, Progress: 45.52% - Loss: 0.1050\n",
            "Epoch 2/2, Progress: 45.86% - Loss: 0.1115\n",
            "Epoch 2/2, Progress: 46.21% - Loss: 0.0616\n",
            "Epoch 2/2, Progress: 46.56% - Loss: 0.0502\n",
            "Epoch 2/2, Progress: 46.91% - Loss: 0.1606\n",
            "Epoch 2/2, Progress: 47.25% - Loss: 0.1385\n",
            "Epoch 2/2, Progress: 47.60% - Loss: 0.0749\n",
            "Epoch 2/2, Progress: 47.95% - Loss: 0.2131\n",
            "Epoch 2/2, Progress: 48.30% - Loss: 0.1456\n",
            "Epoch 2/2, Progress: 48.64% - Loss: 0.1281\n",
            "Epoch 2/2, Progress: 48.99% - Loss: 0.1209\n",
            "Epoch 2/2, Progress: 49.34% - Loss: 0.1031\n",
            "Epoch 2/2, Progress: 49.69% - Loss: 0.1184\n",
            "Epoch 2/2, Progress: 50.03% - Loss: 0.0780\n",
            "Epoch 2/2, Progress: 50.38% - Loss: 0.1060\n",
            "Epoch 2/2, Progress: 50.73% - Loss: 0.1706\n",
            "Epoch 2/2, Progress: 51.07% - Loss: 0.0921\n",
            "Epoch 2/2, Progress: 51.42% - Loss: 0.1393\n",
            "Epoch 2/2, Progress: 51.77% - Loss: 0.1594\n",
            "Epoch 2/2, Progress: 52.12% - Loss: 0.1312\n",
            "Epoch 2/2, Progress: 52.46% - Loss: 0.1444\n",
            "Epoch 2/2, Progress: 52.81% - Loss: 0.0927\n",
            "Epoch 2/2, Progress: 53.16% - Loss: 0.1088\n",
            "Epoch 2/2, Progress: 53.51% - Loss: 0.1025\n",
            "Epoch 2/2, Progress: 53.85% - Loss: 0.1173\n",
            "Epoch 2/2, Progress: 54.20% - Loss: 0.1771\n",
            "Epoch 2/2, Progress: 54.55% - Loss: 0.0949\n",
            "Epoch 2/2, Progress: 54.90% - Loss: 0.1079\n",
            "Epoch 2/2, Progress: 55.24% - Loss: 0.1250\n",
            "Epoch 2/2, Progress: 55.59% - Loss: 0.0660\n",
            "Epoch 2/2, Progress: 55.94% - Loss: 0.0841\n",
            "Epoch 2/2, Progress: 56.29% - Loss: 0.1492\n",
            "Epoch 2/2, Progress: 56.63% - Loss: 0.0790\n",
            "Epoch 2/2, Progress: 56.98% - Loss: 0.1497\n",
            "Epoch 2/2, Progress: 57.33% - Loss: 0.1123\n",
            "Epoch 2/2, Progress: 57.68% - Loss: 0.1803\n",
            "Epoch 2/2, Progress: 58.02% - Loss: 0.1249\n",
            "Epoch 2/2, Progress: 58.37% - Loss: 0.0887\n",
            "Epoch 2/2, Progress: 58.72% - Loss: 0.1207\n",
            "Epoch 2/2, Progress: 59.07% - Loss: 0.1162\n",
            "Epoch 2/2, Progress: 59.41% - Loss: 0.1414\n",
            "Epoch 2/2, Progress: 59.76% - Loss: 0.0994\n",
            "Epoch 2/2, Progress: 60.11% - Loss: 0.0769\n",
            "Epoch 2/2, Progress: 60.46% - Loss: 0.1166\n",
            "Epoch 2/2, Progress: 60.80% - Loss: 0.0947\n",
            "Epoch 2/2, Progress: 61.15% - Loss: 0.0813\n",
            "Epoch 2/2, Progress: 61.50% - Loss: 0.1597\n",
            "Epoch 2/2, Progress: 61.85% - Loss: 0.0822\n",
            "Epoch 2/2, Progress: 62.19% - Loss: 0.1205\n",
            "Epoch 2/2, Progress: 62.54% - Loss: 0.0960\n",
            "Epoch 2/2, Progress: 62.89% - Loss: 0.0995\n",
            "Epoch 2/2, Progress: 63.24% - Loss: 0.1088\n",
            "Epoch 2/2, Progress: 63.58% - Loss: 0.1230\n",
            "Epoch 2/2, Progress: 63.93% - Loss: 0.0409\n",
            "Epoch 2/2, Progress: 64.28% - Loss: 0.1276\n",
            "Epoch 2/2, Progress: 64.63% - Loss: 0.1043\n",
            "Epoch 2/2, Progress: 64.97% - Loss: 0.0876\n",
            "Epoch 2/2, Progress: 65.32% - Loss: 0.0774\n",
            "Epoch 2/2, Progress: 65.67% - Loss: 0.1375\n",
            "Epoch 2/2, Progress: 66.02% - Loss: 0.1277\n",
            "Epoch 2/2, Progress: 66.36% - Loss: 0.1400\n",
            "Epoch 2/2, Progress: 66.71% - Loss: 0.1266\n",
            "Epoch 2/2, Progress: 67.06% - Loss: 0.1741\n",
            "Epoch 2/2, Progress: 67.40% - Loss: 0.0853\n",
            "Epoch 2/2, Progress: 67.75% - Loss: 0.0886\n",
            "Epoch 2/2, Progress: 68.10% - Loss: 0.0416\n",
            "Epoch 2/2, Progress: 68.45% - Loss: 0.1392\n",
            "Epoch 2/2, Progress: 68.79% - Loss: 0.1073\n",
            "Epoch 2/2, Progress: 69.14% - Loss: 0.1626\n",
            "Epoch 2/2, Progress: 69.49% - Loss: 0.1095\n",
            "Epoch 2/2, Progress: 69.84% - Loss: 0.1764\n",
            "Epoch 2/2, Progress: 70.18% - Loss: 0.0682\n",
            "Epoch 2/2, Progress: 70.53% - Loss: 0.1496\n",
            "Epoch 2/2, Progress: 70.88% - Loss: 0.0669\n",
            "Epoch 2/2, Progress: 71.23% - Loss: 0.0784\n",
            "Epoch 2/2, Progress: 71.57% - Loss: 0.2071\n",
            "Epoch 2/2, Progress: 71.92% - Loss: 0.1242\n",
            "Epoch 2/2, Progress: 72.27% - Loss: 0.1590\n",
            "Epoch 2/2, Progress: 72.62% - Loss: 0.1323\n",
            "Epoch 2/2, Progress: 72.96% - Loss: 0.1324\n",
            "Epoch 2/2, Progress: 73.31% - Loss: 0.1122\n",
            "Epoch 2/2, Progress: 73.66% - Loss: 0.0952\n",
            "Epoch 2/2, Progress: 74.01% - Loss: 0.1200\n",
            "Epoch 2/2, Progress: 74.35% - Loss: 0.0963\n",
            "Epoch 2/2, Progress: 74.70% - Loss: 0.1387\n",
            "Epoch 2/2, Progress: 75.05% - Loss: 0.0972\n",
            "Epoch 2/2, Progress: 75.40% - Loss: 0.1360\n",
            "Epoch 2/2, Progress: 75.74% - Loss: 0.1324\n",
            "Epoch 2/2, Progress: 76.09% - Loss: 0.1605\n",
            "Epoch 2/2, Progress: 76.44% - Loss: 0.1141\n",
            "Epoch 2/2, Progress: 76.79% - Loss: 0.0770\n",
            "Epoch 2/2, Progress: 77.13% - Loss: 0.1137\n",
            "Epoch 2/2, Progress: 77.48% - Loss: 0.1551\n",
            "Epoch 2/2, Progress: 77.83% - Loss: 0.0914\n",
            "Epoch 2/2, Progress: 78.18% - Loss: 0.0973\n",
            "Epoch 2/2, Progress: 78.52% - Loss: 0.1227\n",
            "Epoch 2/2, Progress: 78.87% - Loss: 0.1341\n",
            "Epoch 2/2, Progress: 79.22% - Loss: 0.0734\n",
            "Epoch 2/2, Progress: 79.57% - Loss: 0.0458\n",
            "Epoch 2/2, Progress: 79.91% - Loss: 0.1256\n",
            "Epoch 2/2, Progress: 80.26% - Loss: 0.0778\n",
            "Epoch 2/2, Progress: 80.61% - Loss: 0.0923\n",
            "Epoch 2/2, Progress: 80.96% - Loss: 0.1196\n",
            "Epoch 2/2, Progress: 81.30% - Loss: 0.0863\n",
            "Epoch 2/2, Progress: 81.65% - Loss: 0.1487\n",
            "Epoch 2/2, Progress: 82.00% - Loss: 0.1555\n",
            "Epoch 2/2, Progress: 82.35% - Loss: 0.1096\n",
            "Epoch 2/2, Progress: 82.69% - Loss: 0.1414\n",
            "Epoch 2/2, Progress: 83.04% - Loss: 0.0735\n",
            "Epoch 2/2, Progress: 83.39% - Loss: 0.0959\n",
            "Epoch 2/2, Progress: 83.74% - Loss: 0.0747\n",
            "Epoch 2/2, Progress: 84.08% - Loss: 0.1736\n",
            "Epoch 2/2, Progress: 84.43% - Loss: 0.1181\n",
            "Epoch 2/2, Progress: 84.78% - Loss: 0.1180\n",
            "Epoch 2/2, Progress: 85.12% - Loss: 0.1410\n",
            "Epoch 2/2, Progress: 85.47% - Loss: 0.0582\n",
            "Epoch 2/2, Progress: 85.82% - Loss: 0.0610\n",
            "Epoch 2/2, Progress: 86.17% - Loss: 0.0886\n",
            "Epoch 2/2, Progress: 86.51% - Loss: 0.0913\n",
            "Epoch 2/2, Progress: 86.86% - Loss: 0.1456\n",
            "Epoch 2/2, Progress: 87.21% - Loss: 0.1242\n",
            "Epoch 2/2, Progress: 87.56% - Loss: 0.0862\n",
            "Epoch 2/2, Progress: 87.90% - Loss: 0.0769\n",
            "Epoch 2/2, Progress: 88.25% - Loss: 0.0964\n",
            "Epoch 2/2, Progress: 88.60% - Loss: 0.1528\n",
            "Epoch 2/2, Progress: 88.95% - Loss: 0.1202\n",
            "Epoch 2/2, Progress: 89.29% - Loss: 0.1031\n",
            "Epoch 2/2, Progress: 89.64% - Loss: 0.0785\n",
            "Epoch 2/2, Progress: 89.99% - Loss: 0.1630\n",
            "Epoch 2/2, Progress: 90.34% - Loss: 0.1096\n",
            "Epoch 2/2, Progress: 90.68% - Loss: 0.1039\n",
            "Epoch 2/2, Progress: 91.03% - Loss: 0.0639\n",
            "Epoch 2/2, Progress: 91.38% - Loss: 0.1551\n",
            "Epoch 2/2, Progress: 91.73% - Loss: 0.1282\n",
            "Epoch 2/2, Progress: 92.07% - Loss: 0.1103\n",
            "Epoch 2/2, Progress: 92.42% - Loss: 0.1288\n",
            "Epoch 2/2, Progress: 92.77% - Loss: 0.1257\n",
            "Epoch 2/2, Progress: 93.12% - Loss: 0.1692\n",
            "Epoch 2/2, Progress: 93.46% - Loss: 0.1276\n",
            "Epoch 2/2, Progress: 93.81% - Loss: 0.1248\n",
            "Epoch 2/2, Progress: 94.16% - Loss: 0.1216\n",
            "Epoch 2/2, Progress: 94.51% - Loss: 0.1234\n",
            "Epoch 2/2, Progress: 94.85% - Loss: 0.1480\n",
            "Epoch 2/2, Progress: 95.20% - Loss: 0.0917\n",
            "Epoch 2/2, Progress: 95.55% - Loss: 0.0972\n",
            "Epoch 2/2, Progress: 95.90% - Loss: 0.0765\n",
            "Epoch 2/2, Progress: 96.24% - Loss: 0.1511\n",
            "Epoch 2/2, Progress: 96.59% - Loss: 0.1062\n",
            "Epoch 2/2, Progress: 96.94% - Loss: 0.1237\n",
            "Epoch 2/2, Progress: 97.29% - Loss: 0.1288\n",
            "Epoch 2/2, Progress: 97.63% - Loss: 0.1491\n",
            "Epoch 2/2, Progress: 97.98% - Loss: 0.0828\n",
            "Epoch 2/2, Progress: 98.33% - Loss: 0.0766\n",
            "Epoch 2/2, Progress: 98.68% - Loss: 0.1425\n",
            "Epoch 2/2, Progress: 99.02% - Loss: 0.0996\n",
            "Epoch 2/2, Progress: 99.37% - Loss: 0.0894\n",
            "Epoch 2/2, Progress: 99.72% - Loss: 0.1606\n",
            "Epoch 2/2, Progress: 100.07% - Loss: 0.0954\n",
            "Model saved to Models/saved_model.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from melanomaCNN import MelanomaCNN\n",
        "# from net_class import Net\n",
        "\n",
        "# Constants\n",
        "IMG_SIZE = 224  # Image dimensions (50x50 pixels)\n",
        "BATCH_SIZE = 32 # Number of samples per batch\n",
        "LEARNING_RATE = 0.0001  # Learning rate for the optimizer\n",
        "EPOCHS = 2  # Number of training epochs\n",
        "\n",
        "# Load training data\n",
        "# Loading the data\n",
        "data = np.load('melanoma_dataset.npz')\n",
        "train_images = data['train_images']\n",
        "train_labels = data['train_labels']\n",
        "test_images = data['test_images']\n",
        "test_labels = data['test_labels']\n",
        "# training_data = np.load(\"melanoma_training_data.npy\", allow_pickle=True)\n",
        "\n",
        "# Prepare input and label tensors\n",
        "train_X = torch.Tensor([item for item in train_images]) / 255.0  # Normalize pixel values to [0, 1]\n",
        "train_y = torch.Tensor([item for item in train_labels])  # One-hot encoded labels\n",
        "\n",
        "# Initialize model, optimizer, and loss function\n",
        "net = MelanomaCNN()\n",
        "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
        "loss_function = nn.MSELoss()  # Mean Squared Error Loss\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Starting epoch {epoch + 1}/{EPOCHS}\")\n",
        "    for i in range(0, len(train_X), BATCH_SIZE):\n",
        "\n",
        "        # Prepare batches\n",
        "        batch_X = train_X[i:i + BATCH_SIZE].view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
        "        batch_y = train_y[i:i + BATCH_SIZE]\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(batch_X)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, batch_y)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print progress\n",
        "        progress = (i + BATCH_SIZE) / len(train_X) * 100\n",
        "    \n",
        "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Progress: {progress:.2f}% - Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "model_path = \"Models/saved_model.pth\"\n",
        "torch.save(net.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([224, 224])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_X[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d34-SA5kVDS",
        "outputId": "72935e30-83d7-45de-a783-6b6d0c4871d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 85.52%\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(train_X), BATCH_SIZE):\n",
        "        batch_X = train_X[i:i + BATCH_SIZE].view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
        "        batch_y = train_y[i:i + BATCH_SIZE]\n",
        "\n",
        "        outputs = net(batch_X)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        labels = torch.argmax(batch_y, dim=1)\n",
        "\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Training Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSvIFZqp3CL",
        "outputId": "e9ac5cd0-4e57-4b31-e407-51796a8ad97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from Models/saved_model.pth\n"
          ]
        }
      ],
      "source": [
        "model_path = 'Models/saved_model.pth'\n",
        "\n",
        "net.load_state_dict(torch.load(model_path))\n",
        "net.eval()\n",
        "print(f\"Model loaded from {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LFLb_SvWrFts"
      },
      "outputs": [],
      "source": [
        "test_X = torch.Tensor([item for item in test_images]) / 255.0  # Normalize pixel values to [0, 1]\n",
        "test_y = torch.Tensor([item for item in test_labels])  # One-hot encoded labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdbO-cx-qvLY",
        "outputId": "d4e5ae19-c617-4f94-e9f6-d0fa56f15fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 85.20%\n"
          ]
        }
      ],
      "source": [
        "net.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for i in range(0, len(test_X), BATCH_SIZE):\n",
        "        batch_X = test_X[i:i + BATCH_SIZE].view(-1, 1, IMG_SIZE, IMG_SIZE)\n",
        "        batch_y = test_y[i:i + BATCH_SIZE]\n",
        "\n",
        "        outputs = net(batch_X)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "        labels = torch.argmax(batch_y, dim=1)\n",
        "\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += batch_y.size(0)\n",
        "\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Testing Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchsummary\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\n",
            "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Installing collected packages: torchsummary\n",
            "Successfully installed torchsummary-1.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xp9ppoBysCeq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 220, 220]             832\n",
            "            Conv2d-2         [-1, 64, 106, 106]          51,264\n",
            "            Conv2d-3          [-1, 128, 49, 49]         204,928\n",
            "            Linear-4                  [-1, 512]      37,749,248\n",
            "            Linear-5                    [-1, 2]           1,026\n",
            "================================================================\n",
            "Total params: 38,007,298\n",
            "Trainable params: 38,007,298\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.19\n",
            "Forward/backward pass size (MB): 19.65\n",
            "Params size (MB): 144.99\n",
            "Estimated Total Size (MB): 164.83\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "# model = model.to('cuda')  # Move to GPU if available\n",
        "summary(net, input_size=(1, 224, 224))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
